{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network activations research\n",
    "\n",
    "This research tries to address 3 topics for neural networks:\n",
    "- test how a single layer neural network can learn a multivariate gaussian distribution\n",
    "- test the impact of the type of the activation on the layer has on the result\n",
    "- implement a new custom activation based on RELU and test its impact - TODO\n",
    "\n",
    "For this research our own library was created named matmih.\n",
    "\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We require at least tensorflow 2.3 and tensorflow-probability 0.11\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "def mount_gdrive():\n",
    "    # Import the library and kaggle config files from gdrive\n",
    "    GDRIVE_PATH='/content/gdrive/RESEARCH'\n",
    "    if 'google.colab' in sys.modules:\n",
    "        from google.colab import drive\n",
    "        import shutil\n",
    "        drive.mount('/content/gdrive')\n",
    "        sys.path.append(GDRIVE_PATH)\n",
    "        os.makedirs('/root/.kaggle/', exist_ok=True)\n",
    "        shutil.copyfile(GDRIVE_PATH + 'kaggle.json', '/root/.kaggle/kaggle.json')\n",
    "        !chmod 600 '/root/.kaggle/kaggle.json'\n",
    "\n",
    "def install_modules():\n",
    "    !pip install --quiet kaggle\n",
    "    !pip install --quiet pandas\n",
    "    !pip install --quiet scikit-learn\n",
    "    !pip install --quiet scikit-image\n",
    "    !pip install --quiet scipy\n",
    "    !pip install --quiet statsmodels\n",
    "    !pip install --upgrade --quiet tensorflow\n",
    "    !pip install --upgrade --quiet tensorflow-probability\n",
    "    !pip install --quiet randomcolor\n",
    "    !pip install --quiet matplotlib\n",
    "    !pip install --quiet Pillow\n",
    "    !pip install --quiet arviz\n",
    "    !pip install --quiet seaborn\n",
    "    !pip install --quiet prettytable\n",
    "\n",
    "mount_gdrive()\n",
    "#install_modules()\n",
    "\n",
    "import matmih as mm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.python.platform.build_info.build_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate normal dataset creation\n",
    "Created a dataset using by sampling from multivariate normal distribution for the features and using a categorical distribution for the classes. Each class will have its own mean and covariance.\n",
    "\n",
    "Since the data distribution is know the best estimator is Bayes so we can compute the baseline best accuracy class as \n",
    "$ argmax(P(C_i) * P_{MVNdistro}(features)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distr_DataSet:\n",
    "    def __init__(self, class_probs, feature_distributions):\n",
    "        assert(len(class_probs) == len(feature_distributions))\n",
    "\n",
    "        self._no_classes = len(class_probs)\n",
    "        self._class_choice = tfp.distributions.Categorical(probs=class_probs)\n",
    "        self._distr = feature_distributions\n",
    "        self._feature_shape = feature_distributions[0].event_shape\n",
    "    \n",
    "    def sample(self, N):\n",
    "        s = np.zeros((N, *self._feature_shape))\n",
    "        choice = self._class_choice.sample(N)\n",
    "        for i in range(N):\n",
    "            s[i] = self._distr[choice[i]].sample(1).numpy().squeeze()\n",
    "        return s, choice.numpy()\n",
    "    \n",
    "    def bayes_classifier(self, features):\n",
    "        classes = np.zeros(len(features), dtype=np.int32)\n",
    "        class_scores = np.array([self._class_choice.prob(i) for i in range(self._no_classes)])\n",
    "        for j, feature in enumerate(features):\n",
    "            scores = np.array([self._distr[i].prob(feature) for i in range(self._no_classes)])\n",
    "            classes[j] = np.argmax(class_scores * scores)\n",
    "        \n",
    "        return classes\n",
    "            \n",
    "\n",
    "class MVNormal_Data(Distr_DataSet):\n",
    "    def __init__(self, class_prob: list, no_features):\n",
    "        features = []\n",
    "        for i in range(len(class_prob)):\n",
    "            unif = tfp.distributions.Uniform(low=[-1] * no_features, high=[5] * no_features)\n",
    "        \n",
    "            loc = unif.sample()\n",
    "\n",
    "            tril=tf.linalg.LinearOperatorLowerTriangular(unif.sample(sample_shape=(no_features,))).to_dense()\n",
    "\n",
    "            distr = tfp.distributions.MultivariateNormalTriL(loc=loc, scale_tril=tril, name='class{}'.format(i))\n",
    "            del unif\n",
    "\n",
    "            features.append(distr)\n",
    "\n",
    "        super(MVNormal_Data, self).__init__(class_prob, features)\n",
    "        \n",
    "# sample a binomial classification dataset\n",
    "data = MVNormal_Data([0.5, 0.5], 5)\n",
    "features, classes = data.sample(1000)\n",
    "bayes_classes = data.bayes_classifier(features)\n",
    "print(\"BAYES ACCURACY {}\".format(mm.Model.accuracy(classes, bayes_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurable NN model\n",
    "Using matmih library we create a configurable neural network model using Keras.\n",
    "\n",
    "All model parameters including the hidden layer size and activation as well as the train epochs, optimier and so on can be configured by passing a hyperparameter dictinary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(mm.TensorModel):\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    def __init__(self, **hyper_params):\n",
    "        self._hyper_params = hyper_params.copy()\n",
    "        no_classes = hyper_params.get('noClasses', 2)\n",
    "        if no_classes == 2:\n",
    "            no_classes = 1\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(hyper_params.get('sizeL1', 10),\n",
    "                                  input_shape=(hyper_params.get('noFeatures', 4),),\n",
    "                                 name='Hidden_1'),\n",
    "            tf.keras.layers.BatchNormalization(name='Hidden_1_BN'),\n",
    "            tf.keras.layers.Activation(hyper_params.get('actL1', 'relu'),\n",
    "                                      name='Hidden_1_Activation'),\n",
    "            tf.keras.layers.Dense(no_classes, name='Output_Logits'),\n",
    "            tf.keras.layers.Activation('softmax', name='softmax')\n",
    "               if no_classes > 1 else\n",
    "            tf.keras.layers.Activation('sigmoid', name='sigmoid')\n",
    "            ], name=hyper_params.get('model_name', 'NN'))\n",
    "        super(NNModel, self).__init__(model, checkpoint=False)\n",
    "\n",
    "        self._train_epochs = hyper_params.get('trainEpochs', 20)\n",
    "        self._optimizer = hyper_params.get('optimizer', tf.keras.optimizers.RMSprop())\n",
    "\n",
    "        # compile the model and initialize the weights\n",
    "        self._model.compile(\n",
    "             optimizer=self._optimizer,\n",
    "             loss='sparse_categorical_crossentropy' if no_classes > 1 else 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "    # Convert the features/target np data to a tensorflow dataset\n",
    "    @staticmethod\n",
    "    def np_to_tf(features, target=None, batch_size=BATCH_SIZE):\n",
    "        if target is None:\n",
    "            ds = tf.data.Dataset.from_tensor_slices( (tf.cast(features, tf.float32)) )\n",
    "        else:\n",
    "            ds = tf.data.Dataset.from_tensor_slices( (tf.cast(features, tf.float32),\n",
    "                                                      tf.cast(target, tf.int32)) )\n",
    "\n",
    "        return ds if batch_size is None else ds.batch(batch_size)\n",
    "\n",
    "    def train(self, data_model, logTensorBoard=False):\n",
    "        callbacks = []\n",
    "        if logTensorBoard:\n",
    "            callbacks += [tf.keras.callbacks.TensorBoard(mm.TensorBoard.get_log_dir(), histogram_freq=1)]\n",
    "\n",
    "        train_ds = NNModel.np_to_tf(data_model.train_features, data_model.train_target)\n",
    "        validation_ds = NNModel.np_to_tf(data_model.validation_features, data_model.validation_target)\n",
    "\n",
    "        history = self._model.fit(train_ds, validation_data=validation_ds,\n",
    "                                  epochs=self._train_epochs, callbacks=callbacks,\n",
    "                                  verbose=self._hyper_params.get('verbose', 1))\n",
    "\n",
    "        return mm.ModelHistory(self._hyper_params, history.history)\n",
    "\n",
    "    def predict(self, features):\n",
    "        features_ds = tf.cast(features, tf.float32)\n",
    "        return self._model.predict_classes(features_ds), self._model.predict(features_ds)\n",
    "\n",
    "# Print the summary of the model used for multiclass classification\n",
    "NNModel(noFeatures=4, noClasses=3, denseSize=5)._model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUReLU - Gaussian Uniform ReLU\n",
    "Inspired from Relu6 activation paper [http://www.cs.utoronto.ca/~kriz/conv-cifar10-aug2010.pdf] we propose a new activation where the constant 6 is replaced by a random variable.\n",
    "\n",
    "Noise added is from a HalfNormal distribution meaning we always increase the activation by some amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "class GU_NNModel(NNModel):\n",
    "    def __init__(self, **hyper_params):\n",
    "        get_custom_objects().update({\n",
    "            'gurelu': tf.keras.layers.Activation(self.gurelu_activation)})\n",
    "\n",
    "        self._threshold = tfp.distributions.Uniform(low=hyper_params.get('low_gurelu', 0.0),\n",
    "                                                    high=(hyper_params.get('high_gurelu', 10.0) \n",
    "                                                    * hyper_params.get('noFeatures', 4)).astype(np.float32))\n",
    "        self._noise = tfp.distributions.HalfNormal(scale=0.5)\n",
    "\n",
    "        super(GU_NNModel, self).__init__(**hyper_params)\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def gurelu_activation(self, x):\n",
    "        max_value = self._threshold.sample((1,1))\n",
    "\n",
    "        @tf.function\n",
    "        def grad(dy):\n",
    "            zero_grad = tf.zeros(shape=(1, dy.shape[1]), dtype=dy.dtype)\n",
    "            dy_grelu = tf.where(tf.math.less(x, 0), zero_grad, dy)\n",
    "            dy_grelu = tf.where(tf.math.greater(x, max_value), zero_grad, dy)\n",
    "            return dy_grelu\n",
    "\n",
    "        min_value = tf.constant(0, shape=(1,1), dtype=x.dtype)\n",
    "        x_relu = tf.clip_by_value(x, min_value, max_value)\n",
    "        x_relu = tf.math.add(x_relu, self._noise.sample((1, x.shape[1])))\n",
    "        return x_relu, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models training and evaluation\n",
    "First we create a binary classification distribution using only 3 featured sampled from the above multivariate normal dataset class.\n",
    "\n",
    "We train and run the models on **independent** samples from the same distribution so that we can correctly do statistical tests on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRAIN_MODEL(NO_CLASSES, NO_FEATURES, ACTIVATIONS, CLASS_PROB: list, MVN_SAMPLES: list):\n",
    "    HISTORY = mm.ModelHistorySet()\n",
    "    PARAMS = {'noFeatures' : NO_FEATURES, 'noClasses' : NO_CLASSES, 'trainEpochs' : 100, 'verbose' : 0}\n",
    "    # the gaussian multivariate distibution dataset\n",
    "    DISTRIBUTION = MVNormal_Data(CLASS_PROB, NO_FEATURES)\n",
    "\n",
    "    for i, no_samples in enumerate(MVN_SAMPLES):\n",
    "        features, classes = DISTRIBUTION.sample(no_samples)\n",
    "        ds = mm.DataModel(features, classes).split([0.8, 0.2])\n",
    "\n",
    "        # Set GUReLU threshold to be the maximum feature value\n",
    "        PARAMS['high_gurelu'] = np.max(ds.train_features).astype(np.float32)\n",
    "\n",
    "        print(\"{}SAMPLES={} BAYES ACCURACY TRAIN={:.3f} VALIDATION={:.3f}{}\".format(\n",
    "            '='*20, no_samples,\n",
    "            mm.Model.accuracy(ds.train_target, DISTRIBUTION.bayes_classifier(ds.train_features)),\n",
    "            mm.Model.accuracy(ds.validation_target, DISTRIBUTION.bayes_classifier(ds.validation_features)),'='*20))\n",
    "\n",
    "        for activation in ACTIVATIONS:\n",
    "            for layer_size in [features.shape[1], 2*features.shape[1], 4*features.shape[1]]:\n",
    "                model = GU_NNModel(model_name='NN_sample{}'.format(i), **PARAMS,\n",
    "                                sizeL1=layer_size, actL1=activation)\n",
    "\n",
    "                history = model.train(ds)\n",
    "                HISTORY.add_history(history)\n",
    "                print('>>>MODEL activation={} dense_layer={:2d} >>> BEST ACCURACY TRAIN={:.3f} VALIDATION={:.3f}'.format(\n",
    "                    activation, layer_size,\n",
    "                    max(history.history('accuracy', mm.DataType.TRAIN)),\n",
    "                    max(history.history('accuracy', mm.DataType.VALIDATION))))\n",
    "                model.destroy()\n",
    "                del model\n",
    "    return HISTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification\n",
    "We train the NN model against 800 samples and validate it against 200 samples taken from a multivariate normal distribution with 4 features using different activation for the single hidden layer.\n",
    "\n",
    "Each class has equal 0.5 probability of sampling and we train the model 6 times on independent samples on the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATIONS = ['gurelu', 'relu', 'tanh', 'softplus']\n",
    "NO_FEATURES = 4\n",
    "NO_CLASSES = 2\n",
    "CLASS_PROB = np.array([1] * NO_CLASSES) / NO_CLASSES\n",
    "NMV_SAMPLES = [1000, 1000, 1000, 1000, 1000, 1000, 1000]\n",
    "\n",
    "HISTORY_2class = TRAIN_MODEL(NO_CLASSES, NO_FEATURES, ACTIVATIONS, CLASS_PROB, NMV_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class classification\n",
    "We train the NN model against 800 samples and validate it against 200 samples taken from a multivariate normal distribution with 10 features using different activation for the single hidden layer.\n",
    "\n",
    "Each class has equal 0.333 probability of sampling and we train the model 6 times on independent samples on the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATIONS = ['gurelu', 'relu', 'tanh', 'softplus']\n",
    "NO_FEATURES = 10\n",
    "NO_CLASSES = 3\n",
    "CLASS_PROB = np.array([1] * NO_CLASSES) / NO_CLASSES\n",
    "NMV_SAMPLES = [1000, 1000, 1000, 1000, 1000, 1000, 1000]\n",
    "\n",
    "HISTORY_3class = TRAIN_MODEL(NO_CLASSES, NO_FEATURES, ACTIVATIONS, CLASS_PROB, NMV_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results of the training\n",
    "Use a continous line for the training set metric and dashed line for validation for each trained sample.\n",
    "\n",
    "We split the results per activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_2 = mm.ModelEvaluation(HISTORY_2class).set_filter_params(['actL1', 'sizeL1'])\n",
    "\n",
    "EVALUATION_2.plot_history('GURELU - 2 class', ['accuracy', 'loss'], actL1='gurelu')\n",
    "EVALUATION_2.plot_history('RELU - 2 class', ['accuracy', 'loss'], actL1='relu')\n",
    "EVALUATION_2.plot_history('TANH - 2 class', ['accuracy', 'loss'], actL1='tanh')\n",
    "EVALUATION_2.plot_history('SOFTPLUS - 2 class', ['accuracy', 'loss'], actL1='softplus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_3 = mm.ModelEvaluation(HISTORY_3class).set_filter_params(['actL1', 'sizeL1'])\n",
    "\n",
    "EVALUATION_3.plot_history('GURELU - 2 class', ['accuracy', 'loss'], actL1='gurelu')\n",
    "EVALUATION_3.plot_history('RELU - 2 class', ['accuracy', 'loss'], actL1='relu')\n",
    "EVALUATION_3.plot_history('TANH - 2 class', ['accuracy', 'loss'], actL1='tanh')\n",
    "EVALUATION_3.plot_history('SOFTPLUS - 2 class', ['accuracy', 'loss'], actL1='softplus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models evaluation\n",
    "We use statistical tests to see if there is any statistical difference between **best accuracy** of the models.\n",
    "\n",
    "To do this we this the data is represented for each model (e.g. model with activation RELU and layer size 12) as the best accuracy given by each of the train-validation accuracy result for each independent sample from the distribution.\n",
    "\n",
    "### Models accuracy distribution\n",
    "Plot the distribution of the best accuracy for each models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========BINARY CLASSIFICATION - 2 class==========\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EVALUATION_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-89343726981e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}BINARY CLASSIFICATION - 2 class{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mEVALUATION_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_distributions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mEVALUATION_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_distributions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVALIDATION\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EVALUATION_2' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"{}BINARY CLASSIFICATION - 2 class{}\".format('='*10, '='*10))\n",
    "EVALUATION_2.plot_distributions('accuracy', mm.DataType.TRAIN)\n",
    "EVALUATION_2.plot_distributions('accuracy', mm.DataType.VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}MULTICLASS CLASSIFICATION - 3 class{}\".format('='*10, '='*10))\n",
    "EVALUATION_3.plot_distributions('accuracy', mm.DataType.TRAIN)\n",
    "EVALUATION_3.plot_distributions('accuracy', mm.DataType.VALIDATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired statistical tests\n",
    "We use a paired statistical tests between each model to check if the mean of the accurary of each is statistically different.\n",
    "To do so we use 2 tests:\n",
    "- Student paired t-test - parametric test that requires that the data is normal distributed.\n",
    "- Wilcoxon signed rank test - non-parametric test that has no data requirement but has less power (larger type II error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}BINARY CLASSIFICATION - 2 class{}\".format('='*10, '='*10))\n",
    "EVALUATION_2.set_p_threshold(0.01)\n",
    "EVALUATION_2.paired_statistical_test('accuracy', mm.DataType.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_2.paired_statistical_test('accuracy', mm.DataType.VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}MULTICLASS CLASSIFICATION - 3 class{}\".format('='*10, '='*10))\n",
    "EVALUATION_3.set_p_threshold(0.01)\n",
    "EVALUATION_3.paired_statistical_test('accuracy', mm.DataType.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_3.paired_statistical_test('accuracy', mm.DataType.VALIDATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anova one-way tests\n",
    "We use anova to check that the mean accuracy of all models (each model is a group) is the same or not.\n",
    "\n",
    "Anova requires the group variances (model accuracies) to be equal so we also perform a Bartlett covariance test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}BINARY CLASSIFICATION - 2 class{}\".format('='*10, '='*10))\n",
    "EVALUATION_2.oneway_anova_test('accuracy', mm.DataType.TRAIN)\n",
    "EVALUATION_2.oneway_anova_test('accuracy', mm.DataType.VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}MULTICLASS CLASSIFICATION - 3 class{}\".format('='*10, '='*10))\n",
    "EVALUATION_3.oneway_anova_test('accuracy', mm.DataType.TRAIN)\n",
    "EVALUATION_3.oneway_anova_test('accuracy', mm.DataType.VALIDATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey honestly significant difference test\n",
    "Anova has the problem that it can only tell use if there is a difference between the mean of all the tests\n",
    "\n",
    "We use Tukey HSD to do pairwise tests same as in the Student t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}BINARY CLASSIFICATION - 2 class{}\".format('='*10, '='*10))\n",
    "EVALUATION_2.tukey_hsd_test('accuracy', mm.DataType.TRAIN)\n",
    "EVALUATION_2.tukey_hsd_test('accuracy', mm.DataType.VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}MULTICLASS CLASSIFICATION - 3 class{}\".format('='*10, '='*10))\n",
    "EVALUATION_3.tukey_hsd_test('accuracy', mm.DataType.TRAIN)\n",
    "EVALUATION_3.tukey_hsd_test('accuracy', mm.DataType.VALIDATION)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
