{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network activations research\n",
    "\n",
    "This research tries to address 3 topics for neural networks:\n",
    "- test how a single layer neural network can learn a multivariate gaussian distribution\n",
    "- test the impact of the type of the activation on the layer has on the result\n",
    "- implement a new custom activation based on RELU with learnable parameters and test its impact\n",
    "- check how initial trainable variables of the custom activation impacts the performance\n",
    "\n",
    "For this research our own library was created named matmih.\n",
    "\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone \"https://glypher:886cd6845d8a78081ae9cd4b6c259722f3b7ca3e@github.com/glypher/matmih.git\"\n",
    "!git -C matmih pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We require at least tensorflow 2.3 and tensorflow-probability 0.11\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import itertools\n",
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "def mount_gdrive():\n",
    "    # Import the library and kaggle config files from gdrive\n",
    "    GDRIVE_PATH='/content/gdrive/RESEARCH'\n",
    "    if 'google.colab' in sys.modules:\n",
    "        from google.colab import drive\n",
    "        import shutil\n",
    "        drive.mount('/content/gdrive')\n",
    "        sys.path.append(GDRIVE_PATH)\n",
    "        os.makedirs('/root/.kaggle/', exist_ok=True)\n",
    "        shutil.copyfile(GDRIVE_PATH + 'kaggle.json', '/root/.kaggle/kaggle.json')\n",
    "        !chmod 600 '/root/.kaggle/kaggle.json'\n",
    "\n",
    "def install_modules():\n",
    "    !pip install --quiet kaggle\n",
    "    !pip install --quiet pandas\n",
    "    !pip install --quiet scikit-learn\n",
    "    !pip install --quiet scikit-image\n",
    "    !pip install --quiet scipy\n",
    "    !pip install --quiet statsmodels\n",
    "    !pip install --upgrade --quiet tensorflow\n",
    "    !pip install --upgrade --quiet tensorflow-probability\n",
    "    !pip install --quiet randomcolor\n",
    "    !pip install --quiet matplotlib\n",
    "    !pip install --quiet Pillow\n",
    "    !pip install --quiet arviz\n",
    "    !pip install --quiet seaborn\n",
    "    !pip install --quiet prettytable\n",
    "\n",
    "mount_gdrive()\n",
    "#install_modules()\n",
    "\n",
    "import matmih as mm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.platform import build_info\n",
    "print(build_info.build_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate normal dataset creation\n",
    "Created a dataset using by sampling from multivariate normal distribution for the features and using a categorical distribution for the classes. Each class will have its own mean and covariance.\n",
    "\n",
    "Since the data distribution is know the best estimator is Bayes so we can compute the baseline best accuracy class as \n",
    "$ argmax(P(C_i) * P_{MVNdistro}(features)) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distr_DataSet:\n",
    "    def __init__(self, class_probs, feature_distributions):\n",
    "        assert(len(class_probs) == len(feature_distributions))\n",
    "\n",
    "        self._no_classes = len(class_probs)\n",
    "        self._class_choice = tfp.distributions.Categorical(probs=class_probs)\n",
    "        self._distr = feature_distributions\n",
    "        self._feature_shape = feature_distributions[0].event_shape\n",
    "    \n",
    "    def sample(self, N):\n",
    "        s = np.zeros((N, *self._feature_shape))\n",
    "        choice = self._class_choice.sample(N)\n",
    "        for i in range(N):\n",
    "            s[i] = self._distr[choice[i]].sample(1).numpy().squeeze()\n",
    "        return s, choice.numpy()\n",
    "    \n",
    "    def bayes_classifier(self, features):\n",
    "        classes = np.zeros(len(features), dtype=np.int32)\n",
    "        class_scores = np.array([self._class_choice.prob(i) for i in range(self._no_classes)])\n",
    "        for j, feature in enumerate(features):\n",
    "            scores = np.array([self._distr[i].prob(feature) for i in range(self._no_classes)])\n",
    "            classes[j] = np.argmax(class_scores * scores)\n",
    "        \n",
    "        return classes\n",
    "            \n",
    "\n",
    "class MVNormal_Data(Distr_DataSet):\n",
    "    def __init__(self, class_prob: list, no_features):\n",
    "        features = []\n",
    "        for i in range(len(class_prob)):\n",
    "            unif = tfp.distributions.Uniform(low=[-1] * no_features, high=[5] * no_features)\n",
    "        \n",
    "            loc = unif.sample()\n",
    "\n",
    "            tril=tf.linalg.LinearOperatorLowerTriangular(unif.sample(sample_shape=(no_features,))).to_dense()\n",
    "\n",
    "            distr = tfp.distributions.MultivariateNormalTriL(loc=loc, scale_tril=tril, name='class{}'.format(i))\n",
    "            del unif\n",
    "\n",
    "            features.append(distr)\n",
    "\n",
    "        super(MVNormal_Data, self).__init__(class_prob, features)\n",
    "        \n",
    "# sample a binomial classification dataset\n",
    "data = MVNormal_Data([0.5, 0.5], 5)\n",
    "features, classes = data.sample(1000)\n",
    "bayes_classes = data.bayes_classifier(features)\n",
    "print(\"BAYES ACCURACY {}\".format(mm.Model.accuracy(classes, bayes_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurable NN model\n",
    "Using matmih library we create a configurable neural network model using Keras.\n",
    "\n",
    "All model parameters including the hidden layer size and activation as well as the train epochs, optimier and so on can be configured by passing a hyperparameter dictinary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(mm.TensorModel):\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    def __init__(self, **hyper_params):\n",
    "        self._hyper_params = hyper_params.copy()\n",
    "        no_classes = hyper_params.get('noClasses', 2)\n",
    "        if no_classes == 2:\n",
    "            no_classes = 1\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(hyper_params.get('sizeL1', 10),\n",
    "                                  input_shape=(hyper_params['noFeatures'],),\n",
    "                                 name='Hidden_1'),\n",
    "            tf.keras.layers.BatchNormalization(name='Hidden_1_BN'),\n",
    "            tf.keras.layers.Activation(hyper_params['actL1'],\n",
    "                                      name='Hidden_1_Activation'),\n",
    "            tf.keras.layers.Dense(no_classes, name='Output_Logits'),\n",
    "            tf.keras.layers.Activation('softmax', name='softmax')\n",
    "               if no_classes > 1 else\n",
    "            tf.keras.layers.Activation('sigmoid', name='sigmoid')\n",
    "            ], name=hyper_params.get('model_name', 'NN'))\n",
    "        super(NNModel, self).__init__(model, checkpoint=False)\n",
    "\n",
    "        self._train_epochs = hyper_params.get('trainEpochs', 50)\n",
    "        self._optimizer = hyper_params.get('optimizer', tf.keras.optimizers.RMSprop())\n",
    "\n",
    "        # compile the model and initialize the weights\n",
    "        self._model.compile(\n",
    "             optimizer=self._optimizer,\n",
    "             loss='sparse_categorical_crossentropy' if no_classes > 1 else 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "    # Convert the features/target np data to a tensorflow dataset\n",
    "    @staticmethod\n",
    "    def np_to_tf(features, target=None, batch_size=BATCH_SIZE):\n",
    "        if target is None:\n",
    "            ds = tf.data.Dataset.from_tensor_slices( (tf.cast(features, tf.float32)) )\n",
    "        else:\n",
    "            ds = tf.data.Dataset.from_tensor_slices( (tf.cast(features, tf.float32),\n",
    "                                                      tf.cast(target, tf.int32)) )\n",
    "\n",
    "        return ds if batch_size is None else ds.batch(batch_size)\n",
    "\n",
    "    def train(self, data_model, logTensorBoard=False):\n",
    "        callbacks = []\n",
    "        if logTensorBoard:\n",
    "            callbacks += [tf.keras.callbacks.TensorBoard(mm.TensorBoard.get_log_dir(), histogram_freq=1)]\n",
    "\n",
    "        train_ds = NNModel.np_to_tf(data_model.train_features, data_model.train_target)\n",
    "        validation_ds = NNModel.np_to_tf(data_model.validation_features, data_model.validation_target)\n",
    "\n",
    "        history = self._model.fit(train_ds, validation_data=validation_ds,\n",
    "                                  epochs=self._train_epochs, callbacks=callbacks,\n",
    "                                  verbose=self._hyper_params.get('verbose', 1))\n",
    "\n",
    "        return mm.ModelHistory(self._hyper_params, history.history)\n",
    "\n",
    "    def predict(self, features):\n",
    "        features_ds = tf.cast(features, tf.float32)\n",
    "        return self._model.predict_classes(features_ds), self._model.predict(features_ds)\n",
    "\n",
    "# Print the summary of the model used for multiclass classification\n",
    "NNModel(noFeatures=4, noClasses=3, denseSize=5, actL1='relu')._model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GUReLU - Gaussian Uniform ReLU\n",
    "Inspired from Relu6 activation paper [http://www.cs.utoronto.ca/~kriz/conv-cifar10-aug2010.pdf] we propose a new activation where the constant 6 is replaced by learnable variable.\n",
    "\n",
    "Noise added is from a Normal distribution meaning we always increase/decrease the activation by some amount.\n",
    "The noise has a learnable scale value and is only used during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GureluActivation(tf.keras.layers.Activation):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GureluActivation, self).__init__(self.gurelu_activation)\n",
    "        self._noise = tfp.distributions.Normal(loc=0.0, scale=1.0)\n",
    "        self._threshold = tf.Variable(np.transpose([kwargs['thresh']] * kwargs['sizeL1']),\n",
    "                                      dtype=tf.float32, trainable=True)\n",
    "        self._noise_scale = tf.Variable(np.transpose([kwargs['scale']] * kwargs['sizeL1']),\n",
    "                                      dtype=tf.float32, trainable=True)\n",
    "        self._is_training = True\n",
    "        self._trainable = kwargs.get('trainable', True)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        self._is_training = training\n",
    "        return self.activation(inputs)\n",
    "\n",
    "    @tf.custom_gradient\n",
    "    def gurelu_activation(self, x):\n",
    "        max_value = self._threshold * x\n",
    "        max_value = tf.where(tf.math.less(max_value, 0.), 0., max_value)\n",
    "\n",
    "        @tf.function\n",
    "        def grad(dy, variables=None):\n",
    "            dy_grelu = tf.where(tf.math.less(x, 0.), 0., dy)\n",
    "            dy_grelu = tf.where(tf.math.greater(x, max_value), 0., dy_grelu)\n",
    "            \n",
    "            if self._trainable:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    tape.watch(dy)\n",
    "                    z = -self._threshold * dy\n",
    "                    grads_thresh = tape.gradient(z, dy)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    tape.watch(dy)\n",
    "                    z = -self._noise_scale * dy\n",
    "                    grads_scale = tape.gradient(z, dy)\n",
    "\n",
    "                var_grads = [tf.reduce_mean(grads_thresh, 0), tf.reduce_mean(grads_scale, 0)]\n",
    "            else:\n",
    "                var_grads = [tf.zeros(variables[0].shape), tf.zeros(variables[1].shape)]\n",
    "            \n",
    "            return dy_grelu, var_grads\n",
    "\n",
    "        x_relu = tf.clip_by_value(x, 0, max_value)\n",
    "        if self._is_training:\n",
    "            x_relu = x_relu + self._noise_scale * self._noise.sample((1, x.shape[1]))\n",
    "        return x_relu, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "class GU_NNModel(NNModel):\n",
    "    def __init__(self, **hyper_params):\n",
    "        if hyper_params['actL1'] == 'gurelu':\n",
    "            get_custom_objects().update({\n",
    "                'gurelu': GureluActivation(**hyper_params)})\n",
    "\n",
    "        super(GU_NNModel, self).__init__(**hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models training and evaluation\n",
    "First we create a binary classification distribution using only 3 featured sampled from the above multivariate normal dataset class.\n",
    "\n",
    "We train and run the models on **independent** samples from the same distribution so that we can correctly do statistical tests on the results.\n",
    "\n",
    "The models are trained for 100 epochs which was empirically chosen so that it passes the overfit threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mm.benchmark\n",
    "def TRAIN_MODEL(NO_CLASSES, NO_FEATURES, ACTIVATIONS, CLASS_PROB: list, MVN_SAMPLES: list):\n",
    "    HISTORY = mm.ModelHistorySet()\n",
    "    PARAMS = {'noFeatures' : NO_FEATURES, 'noClasses' : NO_CLASSES, 'trainEpochs' : 100, 'verbose' : 0}\n",
    "    # the gaussian multivariate distibution dataset\n",
    "    DISTRIBUTION = MVNormal_Data(CLASS_PROB, NO_FEATURES)\n",
    "\n",
    "    for i, no_samples in enumerate(MVN_SAMPLES):\n",
    "        while True:\n",
    "            features, classes = DISTRIBUTION.sample(no_samples)\n",
    "            break\n",
    "            #if mm.Model.accuracy(classes, DISTRIBUTION.bayes_classifier(features)) < 0.99:\n",
    "            #    break\n",
    "        \n",
    "        ds = mm.DataModel(features, classes).split([0.8, 0.2])\n",
    "\n",
    "        print(\"{}SAMPLES={} BAYES ACCURACY TRAIN={:.3f} VALIDATION={:.3f}{}\".format(\n",
    "            '='*20, no_samples,\n",
    "            mm.Model.accuracy(ds.train_target, DISTRIBUTION.bayes_classifier(ds.train_features)),\n",
    "            mm.Model.accuracy(ds.validation_target, DISTRIBUTION.bayes_classifier(ds.validation_features)),'='*20))\n",
    "\n",
    "        for activation in ACTIVATIONS:\n",
    "            NEW_PARAMS = PARAMS.copy()\n",
    "            if isinstance(activation, dict):\n",
    "                act_name = activation['name']\n",
    "                NEW_PARAMS.update(activation)\n",
    "            else:\n",
    "                act_name = activation\n",
    "            \n",
    "            for layer_size in [features.shape[1], 2*features.shape[1], 4*features.shape[1]]:\n",
    "                model = GU_NNModel(model_name='NN_sample{}'.format(i), **NEW_PARAMS,\n",
    "                                sizeL1=layer_size, actL1=act_name)\n",
    "\n",
    "                history = model.train(ds)\n",
    "                HISTORY.add_history(history)\n",
    "                print('>>>MODEL activation={} dense_layer={:2d} >>> BEST ACCURACY TRAIN={:.3f} VALIDATION={:.3f}'.format(\n",
    "                    activation, layer_size,\n",
    "                    max(history.history('accuracy', mm.DataType.TRAIN)),\n",
    "                    max(history.history('accuracy', mm.DataType.VALIDATION))))\n",
    "                model.destroy()\n",
    "                del model\n",
    "    return HISTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification\n",
    "We train the NN model against 800 samples and validate it against 200 samples taken from a multivariate normal distribution with 4 features using different activation for the single hidden layer.\n",
    "\n",
    "Each class has equal 0.5 probability of sampling and we train the model 6 times on independent samples on the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact of non-trainable and trainable threshold and scale\n",
    "Check how the accuracy evolves if we have different values of gurelu threshold and gaussian noise scales in both training and non-training parameter settings\n",
    "\n",
    "Train also against classical activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_CLASSES = 2\n",
    "NO_FEATURES = 4\n",
    "ACTIVATIONS = []\n",
    "CLASS_PROB = np.array([1] * NO_CLASSES) / NO_CLASSES\n",
    "NMV_SAMPLES = [1000, 1000, 1000, 1000, 1000, 1000, 1000]\n",
    "\n",
    "for thresh, scale in list(itertools.product([0.5, 0.7, 0.9], [0., 0.25, 0.5])):\n",
    "    ACTIVATIONS += [{'name':'gurelu', 'thresh':thresh, 'scale':scale, 'trainable':False}]\n",
    "    ACTIVATIONS += [{'name':'gurelu', 'thresh':thresh, 'scale':scale, 'trainable':True}]\n",
    "ACTIVATIONS += ['relu', 'tanh', 'softplus']\n",
    "\n",
    "HISTORY_2class = TRAIN_MODEL(NO_CLASSES, NO_FEATURES, ACTIVATIONS, CLASS_PROB, NMV_SAMPLES)\n",
    "mm.StoreLocal('./history_2class.save').save(HISTORY_2class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class classification\n",
    "We train the NN model against 800 samples and validate it against 200 samples taken from a multivariate normal distribution with 8 features using different activation for the single hidden layer.\n",
    "\n",
    "Each class has equal 0.333 probability of sampling and we train the model 6 times on independent samples on the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_CLASSES = 3\n",
    "NO_FEATURES = 8\n",
    "CLASS_PROB = np.array([1] * NO_CLASSES) / NO_CLASSES\n",
    "NMV_SAMPLES = [1000, 1000, 1000, 1000, 1000, 1000, 1000]\n",
    "\n",
    "for thresh, scale in list(itertools.product([0.5, 0.7, 0.9], [0., 0.25, 0.5])):\n",
    "    ACTIVATIONS += [{'name':'gurelu', 'thresh':thresh, 'scale':scale, 'trainable':False}]\n",
    "    ACTIVATIONS += [{'name':'gurelu', 'thresh':thresh, 'scale':scale, 'trainable':True}]\n",
    "ACTIVATIONS += ['relu', 'tanh', 'softplus']\n",
    "\n",
    "HISTORY_3class = TRAIN_MODEL(NO_CLASSES, NO_FEATURES, ACTIVATIONS, CLASS_PROB, NMV_SAMPLES)\n",
    "mm.StoreLocal('./history_3class.save').save(HISTORY_3class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results of the training\n",
    "Use a continous line for the training set metric and dashed line for validation for each trained sample.\n",
    "\n",
    "We split the results per activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_2 = mm.ModelEvaluation(HISTORY_2class).set_filter_params(['actL1', 'sizeL1'])\n",
    "\n",
    "EVALUATION_2.plot_history('GURELU - 2 class', ['accuracy', 'loss'], actL1='gurelu')\n",
    "EVALUATION_2.plot_history('RELU - 2 class', ['accuracy', 'loss'], actL1='relu')\n",
    "EVALUATION_2.plot_history('TANH - 2 class', ['accuracy', 'loss'], actL1='tanh')\n",
    "EVALUATION_2.plot_history('SOFTPLUS - 2 class', ['accuracy', 'loss'], actL1='softplus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_3 = mm.ModelEvaluation(HISTORY_3class).set_filter_params(['actL1', 'sizeL1'])\n",
    "\n",
    "EVALUATION_3.plot_history('GURELU - 2 class', ['accuracy', 'loss'], actL1='gurelu')\n",
    "EVALUATION_3.plot_history('RELU - 2 class', ['accuracy', 'loss'], actL1='relu')\n",
    "EVALUATION_3.plot_history('TANH - 2 class', ['accuracy', 'loss'], actL1='tanh')\n",
    "EVALUATION_3.plot_history('SOFTPLUS - 2 class', ['accuracy', 'loss'], actL1='softplus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models evaluation\n",
    "We use statistical tests to see if there is any statistical difference between **best accuracy** of the models.\n",
    "\n",
    "To do this we this the data is represented for each model (e.g. model with activation RELU and layer size 12) as the best accuracy given by each of the train-validation accuracy result for each independent sample from the distribution.\n",
    "\n",
    "### Models accuracy distribution\n",
    "Plot the distribution of the best accuracy for each models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"{}BINARY CLASSIFICATION - 2 class{}\".format('='*10, '='*10))\n",
    "EVALUATION_2 = mm.ModelEvaluation(HISTORY_2class).set_filter_params(['actL1', 'sizeL1', 'thresh', 'scale', 'trainable'])\n",
    "NO_FEATURES = 4\n",
    "\n",
    "pb = mm.PlotBuilder().create_subplots(6,1, (20, 100)).set_options(legend_loc='lower right')\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    EVALUATION_2.set_filter_values(sizeL1=dense_size)\n",
    "    data = []\n",
    "    for name, values in EVALUATION_2.results('accuracy', mm.DataType.TRAIN).items():\n",
    "        data.append((values, name))\n",
    "    pb.create_box_plot(f\"TRAIN accuracy DENSE={dense_size}\", *data)\n",
    "\n",
    "    data = []\n",
    "    for name, values in EVALUATION_2.results('accuracy', mm.DataType.VALIDATION).items():\n",
    "        data.append((values, name))\n",
    "    pb.create_box_plot(f\"VALIDATION accuracy DENSE={dense_size}\", *data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}BINARY CLASSIFICATION - 2 class{}\".format('='*10, '='*10))\n",
    "NO_FEATURES = 4\n",
    "EVALUATION_2.set_filter_params(['actL1', 'sizeL1', 'thresh', 'scale', 'trainable'])\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    EVALUATION_2.set_filter_values(sizeL1=dense_size, trainable=True)\n",
    "    EVALUATION_2.plot_distributions('accuracy', mm.DataType.VALIDATION, f\"activation DENSE LAYER={dense_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_3 = mm.ModelEvaluation(HISTORY_2class).set_filter_params(['actL1', 'sizeL1', 'thresh', 'scale', 'trainable'])\n",
    "NO_FEATURES = 8\n",
    "\n",
    "pb = mm.PlotBuilder().create_subplots(6,1, (20, 100)).set_options(legend_loc='lower right')\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    EVALUATION_3.set_filter_values(sizeL1=dense_size)\n",
    "    data = []\n",
    "    for name, values in EVALUATION_3.results('accuracy', mm.DataType.TRAIN).items():\n",
    "        data.append((values, name))\n",
    "    pb.create_box_plot(f\"TRAIN accuracy DENSE={dense_size}\", *data)\n",
    "\n",
    "    data = []\n",
    "    for name, values in EVALUATION_3.results('accuracy', mm.DataType.VALIDATION).items():\n",
    "        data.append((values, name))\n",
    "    pb.create_box_plot(f\"VALIDATION accuracy DENSE={dense_size}\", *data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}MULTICLASS CLASSIFICATION - 3 class{}\".format('='*10, '='*10))\n",
    "NO_FEATURES = 8\n",
    "EVALUATION_3.set_filter_params(['actL1', 'sizeL1', 'thresh', 'scale', 'trainable'])\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    EVALUATION_3.set_filter_values(sizeL1=dense_size, trainable=True)\n",
    "    EVALUATION_3.plot_distributions('accuracy', mm.DataType.VALIDATION, f\"activation DENSE LAYER={dense_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired statistical tests\n",
    "We use a paired statistical tests between each model to check if the mean of the accurary of each is statistically different.\n",
    "To do so we use 2 tests:\n",
    "- Student paired t-test - parametric test that requires that the data is normal distributed.\n",
    "- Wilcoxon signed rank test - non-parametric test that has no data requirement but has less power (larger type II error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}BINARY CLASSIFICATION - 2 class{}\".format('='*10, '='*10))\n",
    "NO_FEATURES = 4\n",
    "EVALUATION_2.set_p_threshold(0.01)\n",
    "EVALUATION_2.set_filter_params(['actL1', 'thresh', 'scale'])\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    EVALUATION_2.set_filter_values(sizeL1=dense_size, trainable=True)\n",
    "    EVALUATION_2.paired_statistical_test('accuracy', mm.DataType.VALIDATION, f\"for DENSE SIZE={dense_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}MULTICLASS CLASSIFICATION - 3 class{}\".format('='*10, '='*10))\n",
    "NO_FEATURES = 8\n",
    "EVALUATION_3.set_p_threshold(0.01)\n",
    "EVALUATION_3.set_filter_params(['actL1', 'thresh', 'scale'])\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    EVALUATION_2.set_filter_values(sizeL1=dense_size, trainable=True)\n",
    "    EVALUATION_2.paired_statistical_test('accuracy', mm.DataType.VALIDATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anova one-way tests\n",
    "We use anova to check that the mean accuracy of all models (each model is a group) is the same or not.\n",
    "\n",
    "Anova requires the group variances (model accuracies) to be equal so we also perform a Bartlett covariance test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}BINARY CLASSIFICATION - 2 class{}\".format('='*10, '='*10))\n",
    "NO_FEATURES = 4\n",
    "EVALUATION_2.set_filter_params(['actL1', 'thresh', 'scale'])\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    EVALUATION_2.set_filter_values(sizeL1=dense_size, trainable=True)\n",
    "    EVALUATION_2.oneway_anova_test('accuracy', mm.DataType.VALIDATION, f\"for DENSE SIZE={dense_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}MULTICLASS CLASSIFICATION - 3 class{}\".format('='*10, '='*10))\n",
    "NO_FEATURES = 8\n",
    "EVALUATION_3.set_filter_params(['actL1', 'thresh', 'scale'])\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    EVALUATION_3.set_filter_values(sizeL1=dense_size, trainable=True)\n",
    "    EVALUATION_3.oneway_anova_test('accuracy', mm.DataType.VALIDATION, f\"for DENSE SIZE={dense_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey honestly significant difference test\n",
    "Anova has the problem that it can only tell use if there is a difference between the mean of all the tests\n",
    "\n",
    "We use Tukey HSD to do pairwise tests same as in the Student t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}BINARY CLASSIFICATION - 2 class{}\".format('='*10, '='*10))\n",
    "NO_FEATURES = 4\n",
    "EVALUATION_2.set_filter_params(['actL1', 'thresh', 'scale'])\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    print(f\"DENSE SIZE={dense_size}\")\n",
    "    EVALUATION_2.set_filter_values(sizeL1=dense_size, trainable=True)\n",
    "    EVALUATION_2.tukey_hsd_test('accuracy', mm.DataType.VALIDATION, f\"for DENSE SIZE={dense_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}MULTICLASS CLASSIFICATION - 3 class{}\".format('='*10, '='*10))\n",
    "NO_FEATURES = 8\n",
    "EVALUATION_3.set_filter_params(['actL1', 'thresh', 'scale'])\n",
    "\n",
    "for dense_size in [NO_FEATURES, 2*NO_FEATURES, 4*NO_FEATURES]:\n",
    "    print(f\"DENSE SIZE={dense_size}\")\n",
    "    EVALUATION_3.set_filter_values(sizeL1=dense_size, trainable=True)\n",
    "    EVALUATION_3.tukey_hsd_test('accuracy', mm.DataType.VALIDATION, f\"for DENSE SIZE={dense_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " %load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matmih as mm\n",
    "import importlib\n",
    "importlib.reload(mm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
